{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExchangeCourseReader.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8pjLCLHLUKmF",
        "nG63qPFVVufa",
        "PCWoZUQQWBl_",
        "uMfqA4QBWK7m",
        "e9boSqGRWT1H",
        "VCkmuk2FWgvS",
        "qvAktgWzqhf8",
        "Y6pVxCHgrI-Z",
        "v5xY7O64rgwD",
        "tUYr--umr8Ge",
        "9KfnGupWsi0v"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pjLCLHLUKmF"
      },
      "source": [
        "# 1. Installing Neccessary Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrxlld7uHZqz",
        "outputId": "4cddaea1-9798-43f7-a9f2-de421e154813",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!sudo apt install tesseract-ocr\r\n",
        "!sudo apt install libtesseract-dev\r\n",
        "!apt install poppler-utils\r\n",
        "!pip install PyPDF2 pytesseract opencv-python pdf2image pysimplegui"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 1s (4,587 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 146442 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 2 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 2,755 kB of archives.\n",
            "After this operation, 13.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libleptonica-dev amd64 1.75.3-3 [1,308 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtesseract-dev amd64 4.00~git2288-10f4998a-2 [1,447 kB]\n",
            "Fetched 2,755 kB in 1s (2,876 kB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_TN0r-FlF2I"
      },
      "source": [
        "!pip install spacy --upgrade\r\n",
        "# You might need to restart the runtime after running this line by using \"Ctrl+M\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVO-OQ4X64J4"
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG63qPFVVufa"
      },
      "source": [
        "# 2. Download Demo Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zuj3tERyWl-M"
      },
      "source": [
        "!git clone https://github.com/teovercesi/SHSG_WinterSchool_GroupProject_PDF_Files /content/pdfs\r\n",
        "# changing working directory into the /content/pdf/ to be able to read from this directory\r\n",
        "%cd pdfs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCWoZUQQWBl_"
      },
      "source": [
        "# 3. Main Program\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMfqA4QBWK7m"
      },
      "source": [
        "## 3.1 Importing modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zxXZ9Q9WS3C"
      },
      "source": [
        "import PyPDF2\r\n",
        "import os\r\n",
        "import spacy\r\n",
        "import cv2\r\n",
        "import pytesseract\r\n",
        "from pdf2image import convert_from_path\r\n",
        "from termcolor import colored\r\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9boSqGRWT1H"
      },
      "source": [
        "## 3.2 Surpress Warnings for Demo Puposes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgDrFmLPWdGl"
      },
      "source": [
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCkmuk2FWgvS"
      },
      "source": [
        "## 3.3 Defining the Course Catalogues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij97C1DIqSE4"
      },
      "source": [
        "# The following lists are to be used for Keyword searching:\r\n",
        "# de denotes the \"Deutsch\"- Track\r\n",
        "# en denotes the \"English\" Track\r\n",
        "# den denotes Tracks that are in both languages\r\n",
        "# General lists to find info on course structures:\r\n",
        "general_de = [\"Pflichtveranstaltung\", \"Pflichtfach\", \"Pflichtwahl\", \"Wahlbereich\", \"Kontextstudium\", \"Fokusbereich\",\r\n",
        "              \"Sprachen\", \"Skills\", \"REKO\"]\r\n",
        "general_de = [each_string.lower() for each_string in general_de]\r\n",
        "\r\n",
        "general_en = [\"Core studies\", \"Compulsory subjects\", \"Contextual Studies\", \"Languages\", \"Skills\", \"REKO\"]\r\n",
        "general_en = [each_string.lower() for each_string in general_en]\r\n",
        "\r\n",
        "# Alternative Search Keywords:\r\n",
        "# alt_list = [\"Kurse\", \"Study\", \"Academics\", \"ECTS\", \"Kursname\"]\r\n",
        "# alt_list = [each_string.lower() for each_string in alt_list]\r\n",
        "\r\n",
        "# Lists for the Business Students (According to the new Study Order:\r\n",
        "# https://universitaetstgallen.sharepoint.com/sites/BachelorDE/SitePages/BWL-Curriculum.aspx)\r\n",
        "\r\n",
        "bbwl_de = [\"mikroökonomik\", \"makroökonomik\", \"statistik\", \"leadership & human resource management\",\r\n",
        "           \"strategisches management\", \"management\", \"empirische sozialforschung\", \"marketing\",\r\n",
        "           \"corporate finance\", \"finance\", \"accounting\", \"controlling\", \"auditing\", \"operations-management\",\r\n",
        "           \"wirtschafts & und steuerrecht\", \"informatik für wirtschaftswissenschaftler\",\r\n",
        "           \"methoden der informatik für wirtschaftswissenschaftler\"]\r\n",
        "bbwl_de = [each_string.lower() for each_string in bbwl_de]\r\n",
        "\r\n",
        "bbwl_en = [\"business and fiscal law\", \"introduction to operations management\", \"accounting\", \"controlling\", \"auditing\",\r\n",
        "           \"corporate finance\",\r\n",
        "           \"methods of informatics for business studies\", \"fundamentals of informatics for business studies\",\r\n",
        "           \"Microeconomics\", \"Macroeconomics\", \"Statistics\",\r\n",
        "           \"Leadership& Human Resource Management\", \"Strategic Management\", \"Social Science Research\", \"Marketing\"]\r\n",
        "bbwl_en = [each_string.lower() for each_string in bbwl_en]\r\n",
        "\r\n",
        "# List for the International Affairs Students :\r\n",
        "# https://universitaetstgallen.sharepoint.com/sites/BachelorDE/SitePages/BIA-Curriculum-und-Reform-O20.aspx\r\n",
        "bia_den = [\"Quantitative Methods\", \"Quantitative Methoden\", \"Mikroökonomik\", \"Microeconomics\", \"Comparative Politics\",\r\n",
        "           \"Vergleichende Politikwissenschaft\", \"Politische Theorie\",\r\n",
        "           \"Public Management\", \"Qualitative Methoden\", \"Qualitative Methods\", \"International Economics\",\r\n",
        "           \"European Governance\", \"Regieren in Europa\", \"International Relations\",\r\n",
        "           \"Macroeconomics\", \"Makroökonomik\", \"International Law\", \"Accounting, Controlling, Auditing\"]\r\n",
        "\r\n",
        "bia_den = [each_string.lower() for each_string in bia_den]\r\n",
        "\r\n",
        "# Lists for the Economics Students:\r\n",
        "# https://universitaetstgallen.sharepoint.com/sites/BachelorDE/SitePages/VWL-Ordnung%2019.aspx\r\n",
        "bvwl_de = [\"Data Handling: Cleaning, Import and Visualization\", \"Data Analytics: Statistik\", \"Makroökonomik\",\r\n",
        "           \"Mikroökonomik\", \"Accounting, Controlling, Auditing\",\r\n",
        "           \"Empirische Wirtschaftsforschung\", \"Makroökonomik\", \"Mikroökonomik\"]\r\n",
        "\r\n",
        "bvwl_de = [each_string.lower() for each_string in bvwl_de]\r\n",
        "\r\n",
        "bvwl_en = [\"Data Handling: Cleaning, Import and Visualization\", \"Data Analytics: Statistics\", \"Macroeconomics\",\r\n",
        "           \"Microeconomics\", \"Accounting, Controlling, Auditing\",\r\n",
        "           \"Empirical Economic Research\", \"Macroeconomics\", \"Microeconomics\"]\r\n",
        "\r\n",
        "bvwl_en = [each_string.lower() for each_string in bvwl_en]\r\n",
        "\r\n",
        "# List for the Law & Economics Students:\r\n",
        "# https://universitaetstgallen.sharepoint.com/sites/BachelorDE/SitePages/BLE-Austausch.aspx\r\n",
        "ble_de = [\"Internationales Recht\", \"Juristische Wahlfächer\", \"Integrationsleistungen\", \"Law & Economics Methode\",\r\n",
        "          \"Law & Economics Methode 2\"]\r\n",
        "\r\n",
        "ble_de = [each_string.lower() for each_string in ble_de]\r\n",
        "\r\n",
        "# List for the Law Students:\r\n",
        "# https://universitaetstgallen.sharepoint.com/sites/BachelorDE/SitePages/BLaw-Austausch.aspx\r\n",
        "blaw = [\"Privatrecht-Wirtschaftsrecht\", \"Verwaltungsrecht IIÖffentliches Wirtschaftsrecht\", \"Öffentliches Recht\",\r\n",
        "        \"Strafrecht BT\", \"Internat. Privatrecht \",\r\n",
        "        \"Völkerrecht\", \"Europarecht\", \"Rechtsgeschichte\"]\r\n",
        "\r\n",
        "blaw = [each_string.lower() for each_string in blaw]\r\n",
        "\r\n",
        "# Moving on to the Masters programmes, there is no structure of specific courses that can be taken abroad. Therefore,\r\n",
        "# Only a general list with all relevant study terms will be passed:\r\n",
        "general_master_de = [\"Fokusbereich\", \"Unabhängiger Wahlbereich\", \"Kontextstudium\", \"Skills\", \"Pflichtwahlkurse\",\r\n",
        "                     \"Pflichtkurse\"]\r\n",
        "\r\n",
        "general_master_en = [\"Independent electives\", \"Concentration Areas\", \"Contextual Studies\", \"Areas of Concentration\",\r\n",
        "                     \"Skills\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvAktgWzqhf8"
      },
      "source": [
        "## 3.4 Recognizing the University Name with AI and creating a File List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejJdjXwPqu18"
      },
      "source": [
        "# implementing AI to extract from input string the name of the university\r\n",
        "def getting_uni_name_with_ai_from_input(a_string):\r\n",
        "    # here we are loading the already trained pipeline\r\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\r\n",
        "    doc = nlp(a_string)\r\n",
        "\r\n",
        "    # preparing our output\r\n",
        "    entities = []\r\n",
        "\r\n",
        "    # if the machine recognizes words based on the trained model it will return the word recognized\r\n",
        "    for word in doc.ents:\r\n",
        "        entities.append(word)\r\n",
        "\r\n",
        "    # we want the output to be a string containing the name of the university\r\n",
        "    return entities[0]\r\n",
        "\r\n",
        "\r\n",
        "# once we have the uni name we must look for those files saved with the uni name inside\r\n",
        "def getting_file_name_from_uni_name(uni_name):\r\n",
        "    # first we look for all the files contained in the directory where we stored all the exchange pdfs\r\n",
        "    files = os.listdir('/content/pdfs/')\r\n",
        "    # then we define a file to search for based on the university name we received as input\r\n",
        "    # IMPORTANT: the pdf file must contain the name of the university in LOWER CASES!!!\r\n",
        "    name_file_to_search = str(uni_name).lower()\r\n",
        "\r\n",
        "    # file_to_find will be our output and so the name of the file relative to the university we looked for\r\n",
        "    # file_to_find = \"\"\r\n",
        "    output_files_list = []\r\n",
        "\r\n",
        "    for file in files:\r\n",
        "        if name_file_to_search in file:\r\n",
        "            # file_to_find = file\r\n",
        "            output_files_list.append(file)\r\n",
        "\r\n",
        "    # here we have now the name of the file which is the input of our pdf conversion and search for keywords\r\n",
        "    if output_files_list:\r\n",
        "        return output_files_list\r\n",
        "    else:\r\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6pVxCHgrI-Z"
      },
      "source": [
        "## 3.5 Converting the PDF Files into Strings to be read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7vqAB_krY0m"
      },
      "source": [
        "def convert_pdf_into_string(file_name):\r\n",
        "\r\n",
        "    # first of all open the pdf file from the directory where it is stored path = os.path.realpath(\r\n",
        "    # r\"C:\\Users\\matte\\PycharmProjects\\SHSG_GroupProject_WinterSchool\\Exchange Files\\\\\" + file_name)\r\n",
        "    pdf_file_object = open(file_name, \"rb\")\r\n",
        "    # print(\"The document to be read is: \" + str(file_name))\r\n",
        "\r\n",
        "    # and making it readable by python\r\n",
        "    reader = PyPDF2.PdfFileReader(pdf_file_object)\r\n",
        "\r\n",
        "    # to create the loop and string we need some preparation\r\n",
        "    num_pages = reader.numPages\r\n",
        "    # print(\"The number of pages is: \" + str(num_pages))\r\n",
        "    count_pages = 0\r\n",
        "    output_text = \"\"\r\n",
        "\r\n",
        "    # the loop reads through all the pages and return the text in a single string\r\n",
        "    while count_pages < num_pages:\r\n",
        "        page_to_read = reader.getPage(count_pages)\r\n",
        "        count_pages += 1\r\n",
        "        output_text += page_to_read.extractText()\r\n",
        "    pdf_file_object.close()\r\n",
        "\r\n",
        "    # if we do not have an empty string after this step then we are good to go\r\n",
        "    if output_text != \"\":\r\n",
        "        output_text = output_text\r\n",
        "\r\n",
        "    # otherwise we are facing probably a PDF where text is not recognizable. To solve this problem we first\r\n",
        "    # convert the PDF into and image and then use an alternative method to read from it\r\n",
        "    else:\r\n",
        "\r\n",
        "        # this is where the conversion of the pdf into an image takes place so that we can read it\r\n",
        "        pages = convert_from_path(file_name, 100)\r\n",
        "        page_number = 1\r\n",
        "\r\n",
        "        # we print one page at the time (get one image at the time) -> otherwise it doesn't work -> poppler is needed\r\n",
        "        # in the process\r\n",
        "        for page in pages:\r\n",
        "            page_name = str(page_number) + \"out.png\"\r\n",
        "            page.save(page_name, \"PNG\")\r\n",
        "            page_number += 1\r\n",
        "\r\n",
        "        # for each image/page that we have printed we extract the text and append it to our text output which is\r\n",
        "        # an empty string at the beginning of the process\r\n",
        "        for i in range(1, page_number):\r\n",
        "            image_to_read = cv2.imread(str(i) + \"out.png\")\r\n",
        "            output_text += pytesseract.image_to_string(image_to_read)\r\n",
        "\r\n",
        "    # due to the fact that we might have some useless punctuations and we are only interested in keywords we clean\r\n",
        "    # most of the punctuations\r\n",
        "    characters_to_remove = [\",\", \".\", \"\\n\", \"\\n\\n\", \"\\t\", \"  \", \"   \", \";\", \"(\", \")\"]\r\n",
        "    for character in characters_to_remove:\r\n",
        "        output_text = output_text.replace(character, \" \")\r\n",
        "\r\n",
        "    # print(\"\\nThe text of your PDF is: \")\r\n",
        "    # print(output_text)\r\n",
        "    return output_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5xY7O64rgwD"
      },
      "source": [
        "## 3.6 Looking for Keywords from Catalaogues in Strings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlidochEr39t"
      },
      "source": [
        "# here we are trying to see if any keyword contained in the catalogue is also in the string (which is our pdf\r\n",
        "# conversion output)\r\n",
        "\r\n",
        "def search_string_for_keyword(a_string, a_catalogue):\r\n",
        "    list_keywords_found = []\r\n",
        "    # keywords_count = 0\r\n",
        "    for keyword in a_catalogue:\r\n",
        "        keyword = keyword.replace(\" \", \"\")\r\n",
        "        if keyword.lower() in a_string.lower():\r\n",
        "            list_keywords_found.append(keyword)\r\n",
        "            # keywords_count += 1\r\n",
        "        else:\r\n",
        "            pass\r\n",
        "    return list_keywords_found"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUYr--umr8Ge"
      },
      "source": [
        "## 3.7 Summarizing our Output - Creating the Lists of Courses Found"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCKUOC4osSu-"
      },
      "source": [
        "# here we take as input the list of files containing the name of the university, the course catalogues of a specific\r\n",
        "# field of study and the catalogue of general study-terms\r\n",
        "def get_list_of_courses(files_list, course_catalogues_for_study_field, general):\r\n",
        "    # course_list is the list of all the courses found in the pdf text\r\n",
        "    course_list = []\r\n",
        "\r\n",
        "    # general_list is the list of all the relevant study-terms\r\n",
        "    general_list = []\r\n",
        "\r\n",
        "    for i in files_list:\r\n",
        "        text = convert_pdf_into_string(i)\r\n",
        "        text = text.replace(\" \", \"\")\r\n",
        "        text = text.lower()\r\n",
        "\r\n",
        "        # here we see if courses contained in each catalogue are reported in the text we get as input\r\n",
        "        for catalogue in course_catalogues_for_study_field:\r\n",
        "            courses_found = search_string_for_keyword(text, catalogue)\r\n",
        "            course_list.append(courses_found)\r\n",
        "\r\n",
        "        # here we see if study-terms contained in each catalogue (of study-terms here) are reported in the text we\r\n",
        "        # get as input\r\n",
        "        for item in general:\r\n",
        "            study_terms_found = search_string_for_keyword(text, item)\r\n",
        "            general_list.append(study_terms_found)\r\n",
        "\r\n",
        "    # Making copies of the lists which have all the results\r\n",
        "    course_list_copy = course_list\r\n",
        "    general_list_copy = general_list\r\n",
        "\r\n",
        "    # Cleaning up the list for final presentation:\r\n",
        "    course_list = [x for x in course_list if x != []]\r\n",
        "    course_list = [item for sublist in course_list for item in sublist]\r\n",
        "    course_list = list(set(course_list))\r\n",
        "\r\n",
        "    general_list = [x for x in general_list if x != []]\r\n",
        "    general_list = [item for sublist in general_list for item in sublist]\r\n",
        "    general_list = list(set(general_list))\r\n",
        "\r\n",
        "    # Printing the overall results:\r\n",
        "    print(\"\")\r\n",
        "    print(\"For the university '\" + colored(str(u_name).upper(), \"green\") + \"', the following \"\r\n",
        "          + colored(\"Courses\", \"blue\") + \" have been found:\")\r\n",
        "    print(course_list)\r\n",
        "    print(\"As to general \" + colored(\"Information about Accreditation\", \"magenta\")\r\n",
        "          + \", the following have been mentioned:\")\r\n",
        "    print(general_list)\r\n",
        "    print(\"\")\r\n",
        "\r\n",
        "    # Ascertaining length of original lists\r\n",
        "    course_list_length = len(course_list_copy)\r\n",
        "    identity_list_length = len(general_list_copy)\r\n",
        "\r\n",
        "    # Yielding the length of the files:\r\n",
        "    files_list_lenght = len(files_list)\r\n",
        "\r\n",
        "    # Getting the separator length:\r\n",
        "    course_len = int(course_list_length / files_list_lenght)\r\n",
        "\r\n",
        "    identity_len = int(identity_list_length / files_list_lenght)\r\n",
        "\r\n",
        "    # Printing which courses are mentioned in which report:\r\n",
        "    old_value_courses = 0\r\n",
        "    old_value_study_terms = 0\r\n",
        "\r\n",
        "    new_value_courses = course_len\r\n",
        "    new_value_study_terms = identity_len\r\n",
        "    pdf_read_count = 1\r\n",
        "\r\n",
        "    for file in files_list:\r\n",
        "        print(\"\" + colored(str(pdf_read_count) + \". \", \"red\") + colored(file, \"yellow\")\r\n",
        "              + \" contains the following \" + colored(\"Courses:\", \"blue\"))\r\n",
        "        pdf_read_count += 1\r\n",
        "\r\n",
        "        if course_list_copy[old_value_courses:new_value_courses] != [[], []]:\r\n",
        "            course_list_copy_temp = [x for x in course_list_copy[old_value_courses:new_value_courses] if x != []]\r\n",
        "            course_list_copy_temp = [i for sub in course_list_copy_temp for i in sub]\r\n",
        "            course_list_copy_temp = list(set(course_list_copy_temp))\r\n",
        "            print(course_list_copy_temp)\r\n",
        "        else:\r\n",
        "            print(None)\r\n",
        "\r\n",
        "        print(\"As to general \" + colored(\"Information about Accreditation\", \"magenta\") + \", the following have been mentioned:\")\r\n",
        "        if general_list_copy[old_value_study_terms:new_value_study_terms] != [[], []]:\r\n",
        "            general_list_copy_temp = [x for x in general_list_copy[old_value_study_terms:new_value_study_terms] if\r\n",
        "                                      x != []]\r\n",
        "            general_list_copy_temp = [i for sub in general_list_copy_temp for i in sub]\r\n",
        "            general_list_copy_temp = list(set(general_list_copy_temp))\r\n",
        "            print(general_list_copy_temp)\r\n",
        "        else:\r\n",
        "            print(None)\r\n",
        "\r\n",
        "        print(\"\")\r\n",
        "\r\n",
        "        # updating the values for the next file item\r\n",
        "        old_value_courses = new_value_courses\r\n",
        "        new_value_courses = new_value_courses + course_len\r\n",
        "\r\n",
        "        old_value_study_terms = new_value_study_terms\r\n",
        "        new_value_study_terms = new_value_study_terms + identity_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KfnGupWsi0v"
      },
      "source": [
        "## 3.8 Executing All the Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEXfrUMds3GW"
      },
      "source": [
        "# This is where the UI begins and we actually run what we developed\r\n",
        "\r\n",
        "# first we use AI to get the university name out of the user input and we make a list of all the files containing\r\n",
        "# the university name\r\n",
        "print(\"Hey! How can I help you with? :)\")\r\n",
        "input_text = input(\"Please, write your question here: \")\r\n",
        "print(\"\")\r\n",
        "\r\n",
        "try:\r\n",
        "  u_name = getting_uni_name_with_ai_from_input(input_text)\r\n",
        "  # f_name = getting_file_name_from_uni_name(u_name)\r\n",
        "  files_list_names = getting_file_name_from_uni_name(u_name)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  if files_list_names is None:\r\n",
        "      print(colored(\"No files found, did you misspell the University name?\", \"red\"))\r\n",
        "      exit()\r\n",
        "\r\n",
        "  # here we ask the study field of the user\r\n",
        "  else:\r\n",
        "      print(\"Please enter whether you are a \" + colored(\"Bachelor\", \"yellow\") + \" or a \" + colored(\"Master\", \"yellow\")\r\n",
        "            + \" Student.\")\r\n",
        "      seniority = input(\"Write here: \")\r\n",
        "      print(\"\")\r\n",
        "\r\n",
        "      if seniority == \"Bachelor\":\r\n",
        "          print(\"Please, tell me your study field\")\r\n",
        "          print(\"You can choose between\" + colored(\" Business\", \"yellow\") + \",\" + colored(\" Economics\", \"yellow\")\r\n",
        "                + \",\" + colored(\" International Affairs\", \"yellow\") + \",\" + colored(\" Law & Economics\", \"yellow\")\r\n",
        "                + \",\" + colored(\" Law\", \"yellow\") + \".\")\r\n",
        "          study_field = input(\"Write here: \")\r\n",
        "          course_catalogue = []\r\n",
        "          if study_field == \"Business\":\r\n",
        "              course_catalogue = [bbwl_de, bbwl_en]\r\n",
        "          elif study_field == \"Economics\":\r\n",
        "              course_catalogue = [bvwl_de, bvwl_en]\r\n",
        "          elif study_field == \"International Affairs\":\r\n",
        "              course_catalogue = [bia_den]\r\n",
        "          elif study_field == \"Law & Economics\":\r\n",
        "              course_catalogue = [ble_de]\r\n",
        "          elif study_field == \"Law\":\r\n",
        "              course_catalogue = [blaw]\r\n",
        "          else:\r\n",
        "              pass\r\n",
        "\r\n",
        "          general_info = [general_en, general_de]\r\n",
        "          get_list_of_courses(files_list_names, course_catalogue, general_info)\r\n",
        "\r\n",
        "      elif seniority == \"Master\":\r\n",
        "          print(\"Since specific Core electives \" + colored(\"cannot be taken outside of UniSG\", \"red\") +\r\n",
        "                \" we will return the Study Terms found in the text: \")\r\n",
        "          print(\"\")\r\n",
        "\r\n",
        "          general_info_master = [general_master_de, general_master_en]\r\n",
        "          master_course_catalogue = [[], []]\r\n",
        "          get_list_of_courses(files_list_names, master_course_catalogue, general_info_master)\r\n",
        "except IndexError:\r\n",
        "  print(colored('Sorry, was not able to recognize the University Name - did you misspell it?', 'red'))\r\n",
        "\r\n",
        "\r\n",
        "# THE END :)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}